{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de84a707-c5e0-45af-a66a-66787b417872",
   "metadata": {},
   "source": [
    "# House Price Prediction With TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c04f6f-6bdb-4cf6-8a4e-64639c262a74",
   "metadata": {},
   "source": [
    "This example demonstrates how the Unfolded Map SDK allows for more engaging exploratory data visualization, helping to simplify the process of building a machine learning model for predicting median house prices in California."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cc8d4-69cb-412f-8727-233d26ad954f",
   "metadata": {},
   "source": [
    "## Dependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b241896e-9cdc-4143-ba2b-3fd303ad05f6",
   "metadata": {},
   "source": [
    "This notebook uses the following dependencies:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- scikit-learn\n",
    "- scipy\n",
    "- seaborn\n",
    "- matplotlib\n",
    "- tensorflow\n",
    "\n",
    "If those aren't already installed, run the following command:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn scipy seaborn matplotlib tensorflow\n",
    "```\n",
    "\n",
    "This notebook was originally tested with the following package versions, but likely works with a broad range of versions:\n",
    "\n",
    "- pandas==1.3.2\n",
    "- numpy==1.19.5\n",
    "- scikit-learn==0.24.2\n",
    "- scipy==1.7.1\n",
    "- seaborn==0.11.2\n",
    "- matplotlib==3.4.3\n",
    "- tensorflow==2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5160c-4f05-4dc1-9e6a-d044dd81947f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c477b-a2e3-4783-b4d7-6771126de879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy.cluster.vq import vq\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax\n",
    "\n",
    "from unfolded.map_sdk import UnfoldedMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794e22f-8b77-4fe5-899e-1f8cb4604099",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135904b7-f8bf-4ffc-96c6-4860dd2a90d9",
   "metadata": {},
   "source": [
    "For this example we'll use data from XXXXXX under the CC0 license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367c4bc-2b9e-4442-a51b-3fb2a2afac78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://actionengine-public.s3.us-east-2.amazonaws.com/housing.csv\"\n",
    "housing = pd.read_csv(dataset_url)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55a1df-8e19-405c-a28a-f61eb42d8167",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58b8d8",
   "metadata": {},
   "source": [
    "First, let's take a look at the input data and try to visualize different aspects of them in a map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddbd66-1710-45f0-a4bc-fc11754720f1",
   "metadata": {},
   "source": [
    "### Population Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9157662-e55d-4b14-8b50-97b77873ca2f",
   "metadata": {},
   "source": [
    "Here we'll create a map that clusters by city with the largest population. Note that since the clustering happens within Unfolded Studio, the clusters change as you zoom in, allowing you to explore your data at various resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_in_CA = UnfoldedMap()\n",
    "\n",
    "# Create a persistent dataset ID that we can reference in both add_dataset and add_layer\n",
    "dataset_id = uuid4()\n",
    "\n",
    "population_in_CA.add_dataset(\n",
    "    {\"uuid\": dataset_id, \"label\": \"Population_in_CA\", \"data\": housing},\n",
    "    auto_create_layers=False,\n",
    ")\n",
    "\n",
    "population_in_CA.add_layer(\n",
    "    {\n",
    "        \"id\": \"population_CA\",\n",
    "        \"type\": \"cluster\",\n",
    "        \"config\": {\n",
    "            \"label\": \"population in CA\",\n",
    "            \"data_id\": dataset_id,\n",
    "            \"columns\": {\"lat\": \"latitude\", \"lng\": \"longitude\"},\n",
    "            \"is_visible\": True,\n",
    "            \"color_scale\": \"quantize\",\n",
    "            \"color_field\": {\"name\": \"population\", \"type\": \"real\"},\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "population_in_CA.set_view_state(\n",
    "    {\"longitude\": -119.417931, \"latitude\": 36.778259, \"zoom\": 5}\n",
    ")\n",
    "\n",
    "population_in_CA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587cfaf-a1be-4940-9c60-d00c31203131",
   "metadata": {},
   "source": [
    "### Distance To Largest Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9f9a7",
   "metadata": {},
   "source": [
    "For example purposes, we'll take the five largest cities in California and compare our input data against these locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitude-latitude pairs for large cities\n",
    "cities = {\n",
    "    \"Los Angeles\": (-118.244, 34.052),\n",
    "    \"San Diego\": (-117.165, 32.716),\n",
    "    \"San Jose\": (-121.895, 37.339),\n",
    "    \"San Francisco\": (-122.419, 37.775),\n",
    "    \"Fresno\": (-119.772, 36.748),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcee73-45b5-4fd8-b668-a2618157a561",
   "metadata": {},
   "source": [
    "Next we need to find the closest city for each row in our data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c99b5-3256-4739-a457-5c670850069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lng1, lat1, lng2, lat2):\n",
    "    \"\"\"Vectorized Haversine formula\n",
    "\n",
    "    Computes distances between two sets of points.\n",
    "\n",
    "    From: https://stackoverflow.com/a/51722117\n",
    "    \"\"\"\n",
    "    # approximate radius of earth in km\n",
    "    R = 6372.8\n",
    "\n",
    "    lat1 = lat1*np.pi/180.0\n",
    "    lng1 = np.deg2rad(lng1)\n",
    "    lat2 = np.deg2rad(lat2)\n",
    "    lng2 = np.deg2rad(lng2)\n",
    "\n",
    "    d = np.sin((lat2 - lat1)/2)**2 + np.cos(lat1)*np.cos(lat2) * np.sin((lng2 - lng1)/2)**2\n",
    "\n",
    "    return 2 * R * np.arcsin(np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c729046-6a42-4241-8fd7-6dac2264ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_city(lng_array, lat_array, cities):\n",
    "    \"\"\"Find the closest_city for each row in lng_array and lat_array input\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "\n",
    "    # Compute distance from each row of arrays to each of our city inputs\n",
    "    for city_name, coord in cities.items():\n",
    "        distances.append(distance(lng_array, lat_array, *coord))\n",
    "\n",
    "    # Convert this list of numpy arrays into a 2D numpy array\n",
    "    distances = np.array(distances)\n",
    "\n",
    "    # Find the shortest distance value for each row\n",
    "    shortest_distances = np.amin(distances, axis=0)\n",
    "\n",
    "    # Find the _index_ of the shortest distance for each row. Then use this value to\n",
    "    # lookup the longitude-latitude pair of the closest city\n",
    "    city_index = np.argmin(distances, axis=0)\n",
    "\n",
    "    # Create a 2D numpy array of location coordinates\n",
    "    # Then use the indexes from above to perform a lookup against the order of cities as\n",
    "    # input. (Note: this relies on the fact that in Python 3.6+ dictionaries are\n",
    "    # ordered)\n",
    "    input_coords = np.array(list(cities.values()))\n",
    "    closest_city_coords = input_coords[city_index]\n",
    "\n",
    "    # Return a 2D array with three columns:\n",
    "    # - Distance to closest city\n",
    "    # - Longitude of closest city\n",
    "    # - Latitude of closest city\n",
    "    return np.hstack((shortest_distances[:, np.newaxis], closest_city_coords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c6f5d-0cab-4881-9612-eacc8327f3bc",
   "metadata": {},
   "source": [
    "Then use the `closest_city` function on our data to create three new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb61de-5a70-4cd9-86c4-3e9686cbf55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[['closest_city_dist', 'closest_city_lng', 'closest_city_lat']] = closest_city(\n",
    "    housing['longitude'], housing['latitude'], cities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0da2d",
   "metadata": {},
   "source": [
    "This map shows the distances between the locations and their nearest big cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_big_cities = UnfoldedMap()\n",
    "dist_data_id = uuid4()\n",
    "\n",
    "distance_to_big_cities.add_dataset(\n",
    "    {\n",
    "        \"uuid\": dist_data_id,\n",
    "        \"label\": \"Distance to closest big cities\",\n",
    "        \"data\": housing,\n",
    "    },\n",
    "    auto_create_layers=False,\n",
    ")\n",
    "\n",
    "distance_to_big_cities.add_layer(\n",
    "    {\n",
    "        \"id\": \"closest_distance\",\n",
    "        \"type\": \"arc\",\n",
    "        \"config\": {\n",
    "            \"data_id\": dist_data_id,\n",
    "            \"label\": \"distance to closest big cities\",\n",
    "            \"columns\": {\n",
    "                \"lng0\": \"longitude\",\n",
    "                \"lat0\": \"latitude\",\n",
    "                \"lng1\": \"closest_city_lng\",\n",
    "                \"lat1\": \"closest_city_lat\",\n",
    "            },\n",
    "            \"visConfig\": {\"opacity\": 0.8, \"thickness\": 0.3},\n",
    "            \"is_visible\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "distance_to_big_cities.set_view_state(\n",
    "    {\"longitude\": -119.417931, \"latitude\": 36.778259, \"zoom\": 4.5}\n",
    ")\n",
    "\n",
    "distance_to_big_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada3234-1d8e-4371-a913-956c009433af",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3191d",
   "metadata": {},
   "source": [
    "Here we are preparing data for training a TensorFlow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop null values as their count is less than 5 %\n",
    "housing.dropna(inplace=True)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"housing_median_age\",\n",
    "        \"total_rooms\",\n",
    "        \"total_bedrooms\",\n",
    "        \"population\",\n",
    "        \"households\",\n",
    "        \"median_income\",\n",
    "        \"ocean_proximity\",\n",
    "    ],\n",
    "    data=housing,\n",
    ")\n",
    "y = pd.DataFrame(columns=[\"median_house_value\"], data=housing)\n",
    "\n",
    "# converting ocean_proximity into new separate columns ('NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND')\n",
    "X = pd.get_dummies(\n",
    "    data=X, columns=[\"ocean_proximity\"], prefix=[\"ocean_proximity\"], drop_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40993536-76e3-4503-af0c-ef26f2676bcc",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7673a78-81da-4bf4-bbca-ba15b2135597",
   "metadata": {
    "tags": []
   },
   "source": [
    "Splitting the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe20ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training data into test, validation and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1\n",
    ")\n",
    "\n",
    "start_values = X_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d9cf3",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd6962-258d-4c18-bb8a-270d03f6aa9f",
   "metadata": {},
   "source": [
    "Using standart scaling with mean and standard deviation from training dataset to avoid data leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e62a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f9308-6d91-475a-83c1-dfbbef814272",
   "metadata": {},
   "source": [
    "## Price Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812992b",
   "metadata": {},
   "source": [
    "Here we are specify the parameters for the TensorFlow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f697f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "number_of_features = X.shape[1]\n",
    "\n",
    "# input Layer\n",
    "model.add(Dense(number_of_features, activation=\"relu\", input_dim=number_of_features))\n",
    "\n",
    "# hidden Layer\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "# output Layer\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc6cb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d0bd8-e34d-427e-b150-53a33a5357f4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f24ea",
   "metadata": {},
   "source": [
    "Here we are starting the model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a020f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train.to_numpy(),\n",
    "    batch_size=10,\n",
    "    epochs=70,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bdd26-7a6a-4564-af3b-c2c0cac3f5b2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb6304",
   "metadata": {},
   "source": [
    "Here we are looking how well the model was trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076a3a4-c154-43ea-a833-6d91ce123bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "loss_train = history.history[\"loss\"]\n",
    "loss_val = history.history[\"val_loss\"]\n",
    "epochs = range(1, 71)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(epochs, loss_train, \"g\", label=\"Training loss\")\n",
    "plt.plot(epochs, loss_val, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e5e9e",
   "metadata": {},
   "source": [
    "In the above chart we can see that the training loss and validation loss are quite close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3474c70",
   "metadata": {},
   "source": [
    "Now we can use the model to predict prices on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c742425",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cbc56",
   "metadata": {},
   "source": [
    "We can see that loss function value on the test data is similar to the loss value on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18756b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87db7d6-d1a3-420d-9ab2-e6e3223a4aeb",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea00a7f",
   "metadata": {},
   "source": [
    "Let's now visualize the predicted numbers on the map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120a0d3-d5d6-4485-aa5b-62275aba026f",
   "metadata": {},
   "source": [
    "First, create a dataframe with predicted values obtained from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = pd.DataFrame(\n",
    "    columns=[\"longitude\", \"latitude\"], data=start_values[[\"longitude\", \"latitude\"]]\n",
    ")\n",
    "predict_data[\"price\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb728127-0c64-4b4e-ab6b-71d451f33513",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94536742",
   "metadata": {},
   "source": [
    "This map shows the predicted prices on houses in CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15e7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_predict_prices = UnfoldedMap()\n",
    "price_data_id = uuid4()\n",
    "\n",
    "housing_predict_prices.add_dataset(\n",
    "    {\n",
    "        \"uuid\": price_data_id,\n",
    "        \"label\": \"Predict housing prices in CA\",\n",
    "        \"data\": predict_data,\n",
    "    },\n",
    "    auto_create_layers=False,\n",
    ")\n",
    "\n",
    "housing_predict_prices.add_layer(\n",
    "    {\n",
    "        \"id\": \"housing_prices\",\n",
    "        \"type\": \"hexagon\",\n",
    "        \"config\": {\n",
    "            \"label\": \"housing prices\",\n",
    "            \"data_id\": price_data_id,\n",
    "            \"columns\": {\"lat\": \"latitude\", \"lng\": \"longitude\"},\n",
    "            \"is_visible\": True,\n",
    "            \"color_scale\": \"quantize\",\n",
    "            \"color_field\": {\"name\": \"price\", \"type\": \"real\"},\n",
    "            \"vis_config\": {\n",
    "                \"colorRange\": {\n",
    "                    \"colors\": [\n",
    "                        \"#E6F598\",\n",
    "                        \"#ABDDA4\",\n",
    "                        \"#66C2A5\",\n",
    "                        \"#3288BD\",\n",
    "                        \"#5E4FA2\",\n",
    "                        \"#9E0142\",\n",
    "                        \"#D53E4F\",\n",
    "                        \"#F46D43\",\n",
    "                        \"#FDAE61\",\n",
    "                        \"#FEE08B\",\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "housing_predict_prices.set_view_state(\n",
    "    {\"longitude\": -119.417931, \"latitude\": 36.6, \"zoom\": 6}\n",
    ")\n",
    "\n",
    "housing_predict_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b897ea-3a74-47bf-bf56-e006e4e0bae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae748c09-3336-4b5d-9d7b-f6b5cd8a3674",
   "metadata": {},
   "source": [
    "Let's cluster the predicted data by price levels using the KMeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "km = KMeans(n_clusters=k, init=\"k-means++\")\n",
    "X = predict_data[[\"latitude\", \"longitude\", \"price\"]]\n",
    "\n",
    "# clustering\n",
    "dtf_X = X.copy()\n",
    "dtf_X[\"cluster\"] = km.fit_predict(X)\n",
    "\n",
    "# add clustering info to the original dataset\n",
    "predict_data[[\"cluster\"]] = dtf_X[[\"cluster\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc816d7f-67c1-4b83-abbb-22784a511164",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e502b33",
   "metadata": {},
   "source": [
    "Let's show the price clusters in a chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    x=\"latitude\",\n",
    "    y=\"longitude\",\n",
    "    data=predict_data,\n",
    "    palette=sns.color_palette(\"bright\", k),\n",
    "    hue=\"cluster\",\n",
    "    size_order=[1, 0],\n",
    "    ax=ax,\n",
    ").set_title(\"Clustering (k=\" + str(k) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619dcb6a",
   "metadata": {},
   "source": [
    "This map shows the same clusters in the geographic context\n",
    "\n",
    "Here we can see that the prices for cities close to the largest cities are the highest, in contrast to those that are far from them and, moreover, far from the ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2897425",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_dataset_id = uuid4()\n",
    "unfolded_map_prices = UnfoldedMap()\n",
    "\n",
    "unfolded_map_prices.add_dataset(\n",
    "    {\"uuid\": prices_dataset_id, \"label\": \"Prices\", \"data\": predict_data},\n",
    "    auto_create_layers=False,\n",
    ")\n",
    "\n",
    "unfolded_map_prices.add_layer(\n",
    "    {\n",
    "        \"id\": \"prices_CA\",\n",
    "        \"type\": \"point\",\n",
    "        \"config\": {\n",
    "            \"data_id\": prices_dataset_id,\n",
    "            \"label\": \"clustering of prices\",\n",
    "            \"columns\": {\"lat\": \"latitude\", \"lng\": \"longitude\"},\n",
    "            \"is_visible\": True,\n",
    "            \"color_scale\": \"quantize\",\n",
    "            \"color_field\": {\"name\": \"cluster\", \"type\": \"real\"},\n",
    "            \"vis_config\": {\n",
    "                \"colorRange\": {\n",
    "                    \"colors\": [\"#7FFFD4\", \"#8A2BE2\", \"#00008B\", \"#FF8C00\", \"#FF1493\"]\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "unfolded_map_prices.set_view_state(\n",
    "    {\"longitude\": -119.417931, \"latitude\": 36.778259, \"zoom\": 4}\n",
    ")\n",
    "\n",
    "unfolded_map_prices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
